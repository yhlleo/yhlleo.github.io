
<!-- saved from url=(0025)http://yhlleo.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>Yahui LIU</title>
  <meta content="Yahui LIU, yhlleo.github.io" name="keywords">
  <style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 12pt;
}
b.paper {
  font-weight: bold;
  font-size: 12pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 900px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 17px;
  font-weight: 700;
  padding-bottom: 0.5em;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  font-weight:bold;
}
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.6em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
  font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}

.paper-title {
    color: #003399;
    font-weight: 500;
}
</style>

<link href="./index_files/css" rel="stylesheet" type="text/css"><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<script async="" src="http://www.google-analytics.com/analytics.js"></script><script async="" src="http://www.google-analytics.com/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-45959174-3', 'yhlleo.github.io');
  ga('send', 'pageview');
</script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script><script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script></head>


<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Yahui Liu" style="float: left; padding-left: .01em; height: 140px;" src="./index_files/YahuiLiu.png">
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Yahui LIU</span><br>
<span><strong>PhD student</strong></span><br>
<span><a href="http://mhug.disi.unitn.it/"> Multimedia and Human Understanding Group (MHUG) </a> <br>
<span>University of Trento & FBK, Italy</span><br>
<span><strong>Address</strong>: Via Sommarive 14, 38123 Povo - Trento, Italy </span><br>
<span><strong>Email  </strong>: yahui.liu [at] unitn.it</span> &nbsp &nbsp 
<a href="https://github.com/yhlleo">Github</a>  &nbsp &nbsp
<a href="https://scholar.google.com/citations?user=P8qd0rEAAAAJ&hl=en">Google Scholar</a></span><br> 
</span></div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<h2>Biography (<a href="http://yhlleo.github.io/index_files/cv.pdf">CV</a>)</h2>
<div class="paper">
Yahui Liu is a PhD student in <a href="http://mhug.disi.unitn.it/">Multimedia and Human Understanding Group (MHUG)</a> at the Department of Information Engineering and Computer Science of the University of Trento, Italy, supervised by Prof. <a href="https://scholar.google.com/citations?hl=en&user=tNtjSewAAAAJ">Nicu Sebe</a> and Dr. <a href="https://scholar.google.com/citations?user=zN5RTZcAAAAJ&hl=en">Bruno Lepri</a>. Before that, he received B.Eng. degree in <i>Photogrammetry and Remote Sensing</i> and M.Eng. degree in <i>Pattern Recognition and Intelligent System</i> from <a href="http://www.whu.edu.cn/">Wuhan University</a> in 2015 and 2018, respectively, under the supervision of Prof. <a href="https://scholar.google.com/citations?hl=en&user=lV0Wxw0AAAAJ">Jian Yao</a>.  His research interests lie in the areas of Computer Vision and Natural Language Processing. Recently, he is working on <b>unsupervised learning</b> and <b>image domain translation</b>.
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
  <ul>
  <li> 5/2021: One paper was accepted to Findings of ACL.
  <li> 3/2021: One paper was accepted to CVPR. </li>
  <li> 1/2021: Chair a Poster Session "Image and signal processing" at <a href="https://www.micc.unifi.it/icpr2020/">ICPR 2020</a> </li>
  <li> 10/2020: One paper was accepted to ICPR. </li>
  <li> 7/2020: Two papers were accepted to ACM MM. </li>
  <li> 3/2020: One paper was submitted to arXiv.</li>
  <li> 7/2019: One paper was accepted to ACM MM.</li>
  <li> 4/2019: One paper was accepted to Sensors. 
  <li> 1/2019: One paper was accepted to Neurocomputing. </li>
  <li> 12/2018: Started my new study journey in the University of Trento, Italy.
  <li> 10/2018: One paper was accepted to TGRS. </li>
  <li> 8/2018: One paper was accepted to EMNLP. </li>
  </ul>
  </div>
</div>
</div>


<div style="clear: both;">
<div class="section">
  <h2>Research Experience</h2>
  <div class="paper">
  <ul> 
    <li><b>Tencent AI Lab</b>, Shenzhen, China. 2021 <br> 
      Mentors: Dr. <a href="https://scholar.google.com/citations?user=xQZMbkUAAAAJ&hl=en">Linchao Bao</a> and Dr. <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en">Wei Bi</a>. <br>
      GANs, Image Domain Translation. </li> 
    <li><b>FBK and MHUG</b>, Trento, Italy. 12/2018 -- 06/2022 <br>
      Mentors: Prof. <a href="https://scholar.google.com/citations?hl=en&user=tNtjSewAAAAJ">Nicu Sebe</a> and Dr. <a href="https://scholar.google.com/citations?user=zN5RTZcAAAAJ&hl=en">Bruno Lepri</a>. <br>
      Deep learning, GANs, Cross-modal Representations, Image Domain Translation. </li>
    <li><b>Tencent AI Lab</b>, Shenzhen, China. 11/2017 -- 09/2018 <br>
      Mentors: Dr. <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en">Wei Bi</a> and Dr. <a href="https://scholar.google.com/citations?user=ukdqC6IAAAAJ&hl=en">Xiaojiang Liu</a>.<br> 
      Deep Learning, Neural Dialogue Generation. </li>
    <li>Computer Vision and Remote Sensing (<b>CVRS</b>) Lab, Wuhan, China. 03/2015 -- 06/2018<br> 
      Mentor: Prof. <a href="https://scholar.google.com/citations?hl=en&user=lV0Wxw0AAAAJ">Jian Yao</a>. <br> 
      Deep Learning, Remote Sensing. </li>
  </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
  <h2>Publications</h2>

  <h3 id="confpapers">&#10022 <i>Conferences</i></h3>  
  <div class="paper">
  <ul>
    <li>
      <span class="paper-title">Assessing Dialogue Systems with Distribution Distances</span>. <br>
      Jiannan Xiang*, <b>Yahui Liu</b>*, Deng Cai, Huayang Li, Defu Lian and Lemao Liu <br>
      (*denotes equal contribution) <br>
      <i>to appear in Findings of the Association for Computational Linguistics</i>(<b>Findings of ACL</b>), 2021. <br>
      <a href="https://arxiv.org/pdf/2105.02573.pdf">[arXiv]</a><a href="https://github.com/yhlleo/frechet-bert-distance">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="semantic-guided" style="float: right; padding-right: .01em; width: 300px;" src="./figures/smooth-latent-space.png">
      <span class="paper-title">Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation</span>. <br>
      <b>Yahui Liu</b>, Enver Sangineto, Yajing Chen, Linchao Bao, Haoxian Zhang, Nicu Sebe, Bruno Lepri, Wei Wang,  Marco De Nadai <br>
      <i>to appear in IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>(<b>CVPR</b>), 2021. <br>
      <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Smoothing_the_Disentangled_Latent_Style_Space_for_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.pdf">[paper]</a>
      <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Liu_Smoothing_the_Disentangled_CVPR_2021_supplemental.pdf">[supp]</a>
      <a href="https://drive.google.com/file/d/1PNEym3Zc48trSs6BZzf7s_tkIUC3rGhr/view?usp=sharing">[video]</a>
      <a href="https://github.com/yhlleo/SmoothingLatentSpace">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="semantic-guided" style="float: right; padding-right: .01em; width: 300px;" src="./figures/semantic-guided.png">
      <span class="paper-title">Semantic-Guided Inpainting Network for Complex Urban Scenes Manipulation</span>. <br>
      Pierfrancesco Ardino, <b>Yahui Liu</b>, Elisa Ricci, Bruno Lepri, Marco De Nadai <br>
      <i>International Conference on Pattern Recognition</i>(<b>ICPR</b>), 2020. <br> 
      <a href="https://arxiv.org/abs/2010.09334">[arXiv]</a> <a href="https://github.com/PierfrancescoArdino/SGINet">[code]</a>
    </li>
  </ul>
  </div>
    
  <div class="paper">
  <ul>
    <li>
      <img title="dwcgan" style="float: right; padding-right: .01em; width: 300px;" src="./figures/discribe-what-to-change.png">
      <span class="paper-title">Describe What to Change: A Text-guided Unsupervised Image-to-Image Translation Approach</span>. <br>
      <b>Yahui Liu</b>, Marco De Nadai, Deng Cai, Huayang Li, Xavier Alameda-Pineda, Nicu Sebe, and Bruno Lepri. <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Oral), 2020. <br>
      <a href="https://arxiv.org/abs/2008.04200">[arXiv]</a><a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413505">[paper]</a><a href="https://github.com/yhlleo/DWC-GAN">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>
    <li>
      <img title="rg-unit" style="float: right; padding-right: .01em; width: 300px;" src="./figures/retrieval-guided.png">
      <span class="paper-title">Retrieval Guided Unsupervised Multi-domain Image-to-Image Translation</span>. <br>
      Raul Gomez*, <b>Yahui Liu</b>*, Marco De Nadai, Dimosthenis Karatzas, Nicu Sebe, and Bruno Lepri. <br>
      (*denotes equal contribution) <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Poster), 2020.
      <a href="http://arxiv.org/abs/2008.04991">[arXiv]</a><a href="https://dl.acm.org/doi/10.1145/3394171.3413785">[paper]</a><a href="https://github.com/yhlleo/RG-UNIT">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <img title="g2g" style="float: right; padding-right: .01em; width: 280px;" src="./figures/gesture-to-gesture.png">
      <span class="paper-title">Gesture-to-Gesture Translation in the Wild via Category-Independent Conditional Maps</span>. <br>
      <b>Yahui Liu</b>, Marco De Nadai, Gloria Zen, Nicu Sebe, and Bruno Lepri. <br>
      <i>ACM International Conference on Multimedia</i>(<b>ACM MM</b>, Poster), 2019. <br>
      <a href="https://arxiv.org/pdf/1907.05916.pdf">[arXiv]</a><a href="https://dl.acm.org/doi/10.1145/3343031.3351020">[paper]</a><a href="https://github.com/yhlleo/TriangleGAN">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <span class="paper-title">Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method</span>. <br>
      <b>Yahui Liu</b>, Victoria Bi, Jun Gao, Xiaojiang Liu, Jian Yao, and Shuming Shi. <br>
      <i>Conference on Empirical Methods in Natural Language Processing</i>(<strong>EMNLP</strong>, Oral), 2018. <br>
      <a href="https://www.aclweb.org/anthology/D18-1297.pdf">[paper]</a><a href="https://github.com/yhlleo/Reweighting">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/vanishing-lines.png">
      <span class="paper-title">2-Line Exhaustive Searching for Real-Time Vanishing Point Estimation in Manhattan World</span>. <br>
      Xiaohu Lu, Jian Yao, Haoang Li, <b>Yahui Liu</b>. <br>
      <i>IEEE Winter Conference on Applications of Computer Vision</i>(<strong>WACV</strong>), 2017. <br>
      <a href="http://yhlleo.github.io/papers/Vanishing_Point_Detection_WACV2017.pdf">[paper]</a><a href="https://github.com/xiaohulugo/VanishingPointDetection">[code]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
  <li>
    <img title="vanishing" style="float: right; padding-right: .01em; width: 280px;" src="./figures/edge-chain.png">
    <span class="paper-title">Edge Chain Detection by Applying Helmholtz Principle on Gradient Magnitude Map</span>. <br>
    Xiaohu Lu, Jian Yao, Li Li, <b>Yahui Liu</b>, and Wei Zhang. <br>
    <i>IAPR International Conference on Pattern Recognition</i>(<strong>ICPR</strong>, Oral), 2016. <br>
    <a href="http://yhlleo.github.io/papers/Edge_Chain_Detection_ICPR2016.pdf">[paper]</a>
  </li>
  </ul>
  </div>

  
  <h3 id="confpapers">&#10022 <i>Journals</i> </h3>
  <div class="paper">
  <ul>  
    <li>
      <img title="vanishing" style="float: right; padding-right: .01em; width: 290px;" src="./figures/license-detection.png">
      <span class="paper-title">Multi-Oriented and Scale-Invariant License Plate Detection Based on Convolutional Neural Networks</span>. <br>
      Jing Han, Jian Yao, Jiao Zhao, Jingmin Tu, and <b>Yahui Liu</b>. <br>
      <strong>Sensors</strong>, Volume: 19, Issue: 5, Page(s): 1175, 2019. (Impact factor: 3.031). <br>
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6427508/">[paper]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul>  
    <li>
      <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/deepcrack.png">
      <span class="paper-title">DeepCrack: A Deep Hierarchical Feature Learning Architecture for Crack Segmentation</span>.<br>
      <b>Yahui Liu</b>, Jian Yao, Rengping Xie, and Li Li. <br>
      <strong>Neurocomputing</strong>, Volume: 338, Page(s): 139-153, 2019. (Impact factor: 4.072). <br>
      <a href="http://yhlleo.github.io/papers/DeepCrack-Neurocomputing2019.pdf">[paper]</a><a href="https://github.com/yhlleo/DeepCrack">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul> 
    <li>
      <img title="vanishing" style="float: right; padding-right: .01em; width: 300px;" src="./figures/roadnet.png">
      <span class="paper-title">RoadNet: Learning to Comprehensively Analyze Road Networks in Complex Urban Scenes From High-Resolution Remotely Sensed Images</span>. <br>
      <b>Yahui Liu</b>, Jian Yao, Xiaohu Lu, Menghan Xia, Xingbo Wang, and Yuan Liu. <br>
      IEEE Transactions on Geoscience and Remote Sensing(<strong>TGRS</strong>), Volume: 57, Issue: 4, Page(s): 2043-2056, 2019. (Impact factor: 5.63). <br>
      <a href="http://yhlleo.github.io/papers/RoadNet-TGRS2019.pdf">[paper]</a><a href="https://github.com/yhlleo/RoadNet">[code & dataset]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul> 
    <li>
      <span class="paper-title">Automatic Multi-image Stitching for Concrete Bridge Inspection by Combining Point and Line Features</span>. <br>
      Renping Xie, Jian Yao, Kang Liu, Xiaohu Lu, <b>Yahui Liu</b>, Menghan Xia, and Qifei Zeng. <br>
      <b>Automation in Construction</b>, Volume: 90, Page(s): 265-280, 2018. (Impact factor: 4.313). 
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0926580518301237">[paper]</a>
    </li>
  </ul>
  </div>

  <div class="paper">
  <ul> 
    <li>
      <span class="paper-title">Optimal Seamline Detection for Orthoimage Mosaicking by Combining Deep Convolutional Neural Network and Graph Cuts</span>. <br>
      Li Li, Jian Yao, <b>Yahui Liu</b>, Wei Yuan, Shuzhu Shi, and Shenggu Yuan. <br>
      <b>Remote Sensing</b>, Volume: 9, Page(s): 701, 2017. (Impact factor: 4.118).
      <a href="https://www.mdpi.com/2072-4292/9/7/701">[paper]</a>
    </li>
  </ul>
  </div> 

  
  
  <h3 id="confpapers">&#10022 <i>Preprint</i></h3>
  <div class="paper">
  <ul>
  <li>
    <span class="paper-title">Adversarial Shape Learning for Building Extraction in VHR Remote Sensing Images</span>. 2021. <br>
    Lei Ding, Hao Tang, <b>Yahui Liu</b>, Yilei Shi, Lorenzo Bruzzone.
    <a href="https://arxiv.org/pdf/2102.11262.pdf">[arXiv]</a>
  </li>
  <li>
    <span class="paper-title">Vanishing Point Guided Natural Image Stitching</span>. 2020. <br>
    Kai Chen, Jian Yao, Jingmin Tu, <b>Yahui Liu</b>, Yinxuan Li, Li Li.
    <a href="https://arxiv.org/pdf/2004.02478.pdf">[arXiv]</a>
  </li>
  <li>
    <span class="paper-title">GMM-UNIT: Unsupervised Multi-Domain and Multi-Modal Image-to-Image Translation via Attribute Gaussian Mixture Modeling</span>. 2020. <br>
    <b>Yahui Liu</b>, Marco De Nadai, Jian Yao, Nicu Sebe, Bruno Lepri, Xavier Alameda-Pineda.
    <a href="https://arxiv.org/pdf/2003.06788.pdf">[arXiv]</a><a href="https://github.com/yhlleo/GMM-UNIT">[code]</a>
  </li>
  <li>
    <span class="paper-title">Fast 3D Line Segment Detection From Unorganized Point Cloud</span>. 2019. <br>
    Xiaohu Lu, <b>Yahui Liu</b>, Kai Li.
    <a href="https://arxiv.org/pdf/1901.02532.pdf">[arXiv]</a><a href="https://github.com/xiaohulugo/3DLineDetection">[code]</a>
  </li>
  </ul>  
  </div>
</div>
</div>



<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Professional Activities</h2>
<div class="paper">
  <h3>Journal Reviewer</h3>
    <ul>
    <li> IEEE Transactions on Industrial Informatics (<b>TII</b>) </li>
    <li> IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>) </li>
    <li> IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>J-STARS</b>) </li>
    </ul>
  <h3>Conference reviewer/TPC member</h3>
  <ul>
    <li> The 31th International Joint Conference on Artificial Intelligence (<b>IJCAI 2022</b>) </li>
    <li> The 29th ACM International Conference on Multimedia (<b>ACM MM 2021</b>) </li>
    <li> IEEE/CVF International Conference on Computer Vision (<b>ICCV 2021</b>) </li>
    <li> IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR 2021</b>) </li>
    <li> The 30th International Joint Conference on Artificial Intelligence (<b>IJCAI 2021</b>) </li>
    <li> The 28th ACM International Conference on Multimedia (<b>ACM MM 2020</b>) </li>
  </ul>
</div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Selected Awards</h2>
<div class="paper">
    <ul>
    <li> Scholarship of the University of Trento, Italy, 2018. </li>
    <li> Excellent Graduate Freshman Scholarship of Wuhan University, China, 2015. </li>
    <li> Outstanding Undergraduate Thesis, Hubei Province, China, 2015 (ratio: 4%). </li>  
    <li> Excellent Undergraduate Students, Wuhan University, China, 2013-2014. </li>
    <li> Excellent Undergraduate Students, Wuhan University, China 2012-2013. </li>
    </ul>
</div>
</div>
</div>


<div style="clear:both;">
<p align="right"><font size="5">Last Updated on 1 May, 2021</font></p>
<p align="right"><font size="5">Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
</div>

<div class="jvectormap-tip"></div></body></html>
